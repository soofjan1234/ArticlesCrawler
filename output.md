In the race to dominate artificial intelligence, it seems there’s no such thing as too much. AI’s next generation will take more terabytes of data, gigawatts of electricity, and hundreds of billions of dollars in talent.

And yet, profits remain scarce, and some economists are warning of an impending bubble. That won’t stop leader OpenAI from striking multibillion-dollar chip deals with Nvidia, AMD, and most recently, Broadcom.

Harvard Business School’s Andy Wu says that while AI’s promise is clear, the potential return on these massive investments remains murky. While some people might be willing to pay a small monthly fee for ChatGPT, subscription revenues are unlikely to cover the costs to scale the technology.

> The problem is that generative AI today has a high variable cost and low variable revenue.

“The problem is that generative AI today has a high variable cost and low variable revenue,” says Wu, the Arjun and Minoo Melwani Family Associate Professor of Business Administration. “One of the things that the general public doesn't think about enough is how ridiculously expensive it is to use generative AI.”

Drawing from his June case study “[AI Wars in 2025](https://www.hbs.edu/faculty/Pages/item.aspx?num=67511),” we asked Wu to discuss the industry’s unique challenges, competitive forces, and potential outcomes. The interview has been lightly edited for clarity and length.

## Could you help us understand the scale of AI’s costs?

Most people are aware of the high fixed cost of training the leading generative AI models, but there are also significant variable costs of “inference” in using generative AI. These inference costs are incurred every time we enter a prompt and receive a response.

To give one example, those Studio Ghibli cartoons that people create with AI? It costs real money to make each of those fun pictures. There are several cents worth of electricity and chip capacity used to make just one image.[OpenAI now expects to spend more than $150 billion on these inference costs through 2030.](https://www.theinformation.com/articles/openai-says-business-will-burn-115-billion-2029)

These are difficult conditions for making money today. Most users receive generative AI for free. The power users do pay, but they pay a flat subscription fee. These business models are a legacy of the last era of software: when the variable cost of software was zero or near-zero, these business models made a lot more sense. They were viable in that you weren’t losing more money as more people used more of your software. Today, the economics are much more difficult.

## Which companies are leading at the moment?

In a gold rush, you coulddig for gold. That’s what most of us immediately gravitate toward. But a gold rush opens up other opportunities: You couldsell shovels, or you couldmake jewelry.

To assess how these opportunities stack up against one another, we can consider how the public markets think about them. From the end of 2022 to today, the biggest winner of gen AI is Nvidia, obviously. Nvidia is the quintessential shovel seller.

After Nvidia, the next biggest winner is Meta, which may come as more of a surprise. And Meta is the quintessential jewelry maker. Generative AI is complementary to the platforms controlled by Meta: social media and advertising today, and perhaps wearables and metaverse in the future. Meta is uniquely positioned to benefit as generative AI technology improves. Meta has done significantly better than Google and Microsoft, even though both are much more traditionally associated with generative AI.

## It sounds like OpenAI is the one digging for gold?

One of the fundamental debates in the field is whether the actual generative AI technology—the model itself or more precisely, the foundation model—is a commodity. I personally subscribe to that viewpoint.

If you subscribe to that viewpoint, then all these companies that we're most excited about, such as OpenAI and Anthropic, face an epic challenge of having to monetize a commodity they invested hundreds of billions of dollars into creating.

But even if you wouldn’t go as far as to say that generative AI is a commodity, one has to admit that there have been some glaring weaknesses in the ability of companies to protect and differentiate their generative AI. The intellectual property regime around all of this is quite weak. Even if you make significant model advancements, it's not clear you can protect it from competitors. In a very short amount of time, ventures like xAI’s Grok and DeepSeek have been able to get close to OpenAI with a much smaller investment.

> Gen AI is exciting because it’s widely available—the barriers to entry are low.

If the barriers to entry in the space remain low, there's not going to be a lot of room for OpenAI and others to raise prices. It would risk handing the market to new entrants willing to provide generative AI at a cheaper price or even free.

All that said, I don't want any of this to be taken as a suggestion that I'm a skeptic about the value creation of gen AI. Gen AI is exciting because it’s widely available—the barriers to entry are low. This means that many will be able to create value with the technology, which also makes it harder for anyone to capture value.

## What business models will likely emerge in AI?

In the end, the most viable business model is something equivalent to pay-for-usage. The issue is that we are not at that point yet in our purchasing behavior.

Software business models regularly evolve, but it takes time for that change to happen. You might remember a time when you could buy a software license on a CD once, and then you could install it anywhere to your heart's delight. After that, we had to make a really annoying transition to the subscription business model, and now we have to pay for software every month and for every user. We will need to make another transition that's going to be even more annoying: eventually, we will pay per instance of usage.

We're already seeing this transition. Today's generative AI “subscriptions” are not true subscriptions because they cap usage, making them, in my view, essentially usage-based models by another name.

The problem is these “subscriptions” are still priced too low to be viable. The typical price point—$20 a month—is not enough to cover variable costs for most of these services. Unfortunately, for the foreseeable future, the pool of people willing to pay $20 a month for generative AI is smaller than the pool of people who would pay $20 a month for Netflix.

That said, I encourage people to use these services as much as they can, while they can. We as users are getting a great deal today on a service subsidized by investors.

## Will it come down to who has the largest language model?

Historically, the theory was that the larger the model, the higher quality it would be. We saw this as OpenAI advanced from GPT-2 to GPT-3 to GPT-4 and in parallel at the other model builders.

These very, very large models do a lot of calculations and contain a lot of information. But in creating these higher-quality models, you also have higher training costs, which are fixed, and you also have higher variable costs of inference. The subscription services limit how many times per day you can use these most computationally intensive models. They limit you because the variable cost is very high. We’ve already reached a point where the variable costs of these largest models are beyond the pale of any known business model available to cover it.

So recent attention has shifted toward developing smaller models that can have comparable quality to a larger model but with a lower variable cost.

## How might the market shake out in the near term?

I wouldn’t be surprised if we experience a reckoning in the coming years. The most hyped AI companies in the space are taking huge losses, and profitability is still far away for most of them. OpenAI and others will need to keep raising money to stay afloat. To attract future investors, they will have to be able to continue growing their valuations to unprecedented levels.

The other canary in the coal mine here is the risk that adjacent players are taking on, which makes them particularly vulnerable to even relatively small shifts in the market. For instance, the rental car company Hertz was especially affected by the pandemic, more than its peers, because it had not only[borrowed money to buy its cars](https://www.wsj.com/articles/hertz-was-already-in-terrible-shape-the-pandemic-finished-it-off-11590434631), but it then took additional loans on top of the cars it bought with borrowed money. So, in some sense, it double-borrowed against its assets.

In AI, we’re seeing hints of that exposure among what we call the “neocloud” companies that provide chips and cloud computing to the AI companies. Even if the market keeps growing, but grows at a slower rate than they’ve anticipated, several of these companies would be underwater.

## How is Google managing its AI investment?

In theory, Google has all the technical capabilities to slam generative AI into everything it does. It is striking that they have chosen not to. Take AI Overviews in Google Search, for example. Google could put them at the top of every Search page. But as they’ve rolled out AI Overviews, one of the fascinating things is that they often pull back on which queries get AI Overviews.

It's not in Google’s short-term financial interest to deploy AI across the board. Instead, Google would prefer to deploy the minimum amount of generative AI possible to dampen its loss of market share to new entrants, but no more than that.

The queries for which generative AI is the most useful are also the queries that Google does not make money on anyway. We're talking about search prompts like, “write my third-grade essay about dinosaurs.” Google makes money on commercial queries, like flight searches and shopping recommendations, for which generative AI today has less of an advantage, if at all, over traditional search.

## What about Meta and Microsoft?

Meta, Amazon, and Microsoft have taken various moves to position themselves to benefit from the rise of generative AI while limiting their own exposure to risks.

Microsoft is the most fascinating one. Most observers assume that Microsoft is a close ally and partner of OpenAI. And yet, Microsoft has invested in or supported several open-source alternatives to OpenAI. So far, Meta has been the open-source leader with its Llama model. Notably, Meta's preferred partner for deploying Llama is Microsoft Azure. Microsoft has also[hired away one of the founders of Google DeepMind](https://www.cnbc.com/2025/07/22/microsoft-google-deepmind-ai-talent.html)to build their own model in house. So, they're able to access some of the behind-the-scenes knowledge of the biggest play at the moment.

## What do you make of talk about a potential AI bubble?

In my research on technology strategy, I’ve closely studied the history of technology over the last 40 years. We’ve seen lots of “bubbles” or “hype cycles” in that time: the dot-com bubble; a sharing economy bubble (for example, WeWork and Bird); a work-from-home pandemic bubble (think Zoom and Peloton); virtual reality; and a bunch of crypto bubbles. The technology industry regularly goes through these ups and downs.

In my view, the definition of a bubble in technology is when everyone can see the valuecreation, but no one is thinking about the valuecapture.

In the late 1990s, there was a company called Pets.com. The gist of it was to mail dog food to people’s homes. This is a wonderful thing. The potential for value creation was very large. But in that hype, we temporarily lost sight of value capture: there was no real business model that made it work at the time. Now, down the road, the economics have improved, allowing Chewy to arrive later and make the business work.

So that would be the risk here: a gap between the immense value creation being projected and how much of that value these companies can actually capture.

Photo credit: Russ Campbell

